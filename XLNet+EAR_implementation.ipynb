{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Parts of the code were inspired by this [BERT Tutorial](https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894#96e0) and adapted to work with XLNet. <br>\n",
        "The EAR technique (i.e. the function def compute_negative_entropy) has been implemented according to the [GitHub repository](https://github.com/g8a9/ear) hosting the code associated with the original [EAR paper](https://aclanthology.org/2022.findings-acl.88/) by Attanasio et al."
      ],
      "metadata": {
        "id": "trOYxpIZr4Pz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9Yu7R24hqgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eaa35d1-aaf5-43fa-88e5-1773b2e30b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.13.1 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SentencePiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets evaluate\n",
        "! pip install SentencePiece\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import trange\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_df = pd.read_csv('/content/drive/My Drive/DATASETS/wiki_toxic/train.csv')\n",
        "validation_df = pd.read_csv('/content/drive/My Drive/DATASETS/wiki_toxic/validation.csv')\n",
        "frac = 0.5\n",
        "#TRAIN\n",
        "print(train_df.shape[0]) # get the number of rows in the dataframe\n",
        "rows_to_delete = train_df.sample(frac=frac, random_state=1) # randomly select half of the rows. Random_state ensures reproducibility\n",
        "train_df = train_df.drop(rows_to_delete.index)\n",
        "print(train_df.shape[0])\n",
        "\n",
        "#VALIDATION\n",
        "print(validation_df.shape[0]) # get the number of rows in the dataframe\n",
        "rows_to_delete = validation_df.sample(frac=frac, random_state=1) # randomly select half of the rows. Random_state ensures reproducibility\n",
        "validation_df = validation_df.drop(rows_to_delete.index)\n",
        "print(validation_df.shape[0])\n",
        "\n",
        "train_text = train_df.comment_text.values\n",
        "train_labels = train_df.label.values\n",
        "validation_text = validation_df.comment_text.values\n",
        "validation_labels = validation_df.label.values"
      ],
      "metadata": {
        "id": "XX6zcblJh5Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#TEST\n",
        "test_df = pd.read_csv('/content/drive/My Drive/DATASETS/wiki_toxic/test.csv')\n",
        "print(test_df.shape[0]) # get the number of rows in the dataframe\n",
        "test_text = test_df.comment_text.values\n",
        "test_labels = test_df.label.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-s-ZjTIjdnO",
        "outputId": "fcd591c1-c157-4560-85c7-e45ab3f08c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "63978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_negative_entropy(\n",
        "    inputs: tuple, attention_mask: torch.Tensor, return_values=False\n",
        "):\n",
        "    \"\"\"Compute the negative entropy across layers of a network for given inputs.\n",
        "\n",
        "    Args:\n",
        "        - input: tuple. Tuple of length num_layers. Each item should be in the form: BHSS\n",
        "        - attention_mask. Tensor with dim: BS\n",
        "    \"\"\"\n",
        "    inputs = torch.stack(inputs)  #  LayersBatchHeadsSeqlenSeqlen\n",
        "    assert inputs.ndim == 5, \"Here we expect 5 dimensions in the form LBHSS\"\n",
        "\n",
        "    #  average over attention heads\n",
        "    pool_heads = inputs.mean(2)\n",
        "\n",
        "    batch_size = pool_heads.shape[1]\n",
        "    samples_entropy = list()\n",
        "    neg_entropies = list()\n",
        "    for b in range(batch_size):\n",
        "        #  get inputs from non-padded tokens of the current sample\n",
        "        mask = attention_mask[b]\n",
        "        sample = pool_heads[:, b, mask.bool(), :]\n",
        "        sample = sample[:, :, mask.bool()]\n",
        "\n",
        "        #  get the negative entropy for each non-padded token\n",
        "        neg_entropy = (sample.softmax(-1) * sample.log_softmax(-1)).sum(-1)\n",
        "        if return_values:\n",
        "            neg_entropies.append(neg_entropy.detach())\n",
        "\n",
        "        #  get the \"average entropy\" that traverses the layer\n",
        "        mean_entropy = neg_entropy.mean(-1)\n",
        "\n",
        "        #  store the sum across all the layers\n",
        "        samples_entropy.append(mean_entropy.sum(0))\n",
        "\n",
        "    # average over the batch\n",
        "    final_entropy = torch.stack(samples_entropy).mean()\n",
        "    if return_values:\n",
        "        return final_entropy, neg_entropies\n",
        "    else:\n",
        "        return final_entropy"
      ],
      "metadata": {
        "id": "7SeWXaYnh_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "train_token_id = []\n",
        "train_attention_masks = []\n",
        "validation_token_id = []\n",
        "validation_attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 250,\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in train_text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  train_token_id.append(encoding_dict['input_ids'])\n",
        "  train_attention_masks.append(encoding_dict['attention_mask'])\n",
        "train_token_id = torch.cat(train_token_id, dim = 0)\n",
        "train_attention_masks = torch.cat(train_attention_masks, dim = 0)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "\n",
        "for sample in validation_text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  validation_token_id.append(encoding_dict['input_ids'])\n",
        "  validation_attention_masks.append(encoding_dict['attention_mask'])\n",
        "validation_token_id = torch.cat(validation_token_id, dim = 0)\n",
        "validation_attention_masks = torch.cat(validation_attention_masks, dim = 0)\n",
        "validation_labels = torch.tensor(validation_labels)"
      ],
      "metadata": {
        "id": "-s5Jgjr0iI-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Recommended batch size: 16, 32\n",
        "batch_size = 32\n",
        "\n",
        "train_idx = np.arange(len(train_labels))\n",
        "val_idx = np.arange(len(validation_labels))\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(train_token_id[train_idx],\n",
        "                          train_attention_masks[train_idx],\n",
        "                          train_labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(validation_token_id[val_idx],\n",
        "                        validation_attention_masks[val_idx],\n",
        "                        validation_labels[val_idx])\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "NZttP-xhiVtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  return b_precision, b_recall"
      ],
      "metadata": {
        "id": "ni5pK7H2iXVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Load the XLNetForSequenceClassification model\n",
        "model = XLNetForSequenceClassification.from_pretrained(\n",
        "    'xlnet-base-cased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = True,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.config.problem_type = \"single_label_classification\" #in this way Cross Entropy loss is selected\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr = 2e-5,\n",
        "                              weight_decay=0.01,\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "0AtTXnaVicqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "\n",
        "    # ========== Training ==========\n",
        "\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = b_input_mask,\n",
        "                             labels = b_labels)\n",
        "\n",
        "        reg_strength = 0.01 #tweak this parameter to apply regularisation. reg_strength = 0.0\n",
        "        neg_entropy = compute_negative_entropy(\n",
        "            inputs=train_output.attentions,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "        reg_loss = reg_strength * neg_entropy\n",
        "        loss = train_output.loss + reg_loss\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids,\n",
        "                              token_type_ids = None,\n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_precision, b_recall = b_metrics(logits, label_ids)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    precision = sum(val_precision)/len(val_precision)\n",
        "    recall = sum(val_recall)/len(val_recall)\n",
        "    f1_score = 2*((precision*recall)/(precision+recall))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(precision) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(recall) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation F1-score: {:.4f}'.format(f1_score) if (precision+recall)!=0 else '\\t - Validation F1-score: NaN')"
      ],
      "metadata": {
        "id": "mZLdMKPkihEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model_save_name = 'FINAL_xlnet_ear_reg_0_01_.bin'\n",
        "path = F\"drive/My Drive/MODELS/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "6LnlR_9Zisw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD MODEL\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "drive.mount('/content/drive')\n",
        "model_save_name = 'FINAL_xlnet_ear_reg_0_01_.bin'\n",
        "path = F\"drive/My Drive/MODELS/{model_save_name}\"\n",
        "# Load the XLNetForSequenceClassification model\n",
        "model = XLNetForSequenceClassification.from_pretrained(\n",
        "    'xlnet-base-cased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = True,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "device = torch.device('cuda')\n",
        "model.load_state_dict(torch.load(path,map_location=device))\n",
        "model.to(device)\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 250,\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )"
      ],
      "metadata": {
        "id": "hVgySiRMb5yV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf6cd5c-f660-48c9-af2c-0b4acd208d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(comment:str):\n",
        "  # We need Token IDs and Attention Mask for inference on the new sentence\n",
        "  test_ids = []\n",
        "  test_attention_mask = []\n",
        "  # Apply the tokenizer\n",
        "  encoding = preprocessing(comment, tokenizer)\n",
        "  # Extract IDs and Attention Mask\n",
        "  test_ids.append(encoding['input_ids'])\n",
        "  test_attention_mask.append(encoding['attention_mask'])\n",
        "  test_ids = torch.cat(test_ids, dim = 0)\n",
        "  test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "  # Forward pass, calculate logit predictions\n",
        "  with torch.no_grad():\n",
        "    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "  prediction = 'TOXIC' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'NON-TOXIC'\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "MTt4lGazb7R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(classifier(\"I am african\"))\n",
        "print(classifier(\"I love african people\"))\n",
        "print(classifier(\"I hate african people\"))\n",
        "print('-')\n",
        "print(classifier(\"I am blind\"))\n",
        "print(classifier(\"I love blind people\"))\n",
        "print(classifier(\"I hate blind people\"))"
      ],
      "metadata": {
        "id": "l8vNHfEU_itA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute F1-score on test dataset"
      ],
      "metadata": {
        "id": "amNxqvso66_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "predictions = []\n",
        "for comment_text in test_text:\n",
        "  result = classifier(comment_text)\n",
        "  if(result=='TOXIC'):\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "print(\"F1-score on test dataset (XLNet 0_01): \"+str(f1_score(test_labels,predictions)))"
      ],
      "metadata": {
        "id": "iyFSdmGh6_6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b0143a-ffa9-4d3f-d264-c31693238248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score on test dataset (XLNet 0_01): 0.6067347249733354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic dataset pre-processing"
      ],
      "metadata": {
        "id": "07lIga6h7I9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "synthetic_test_df = pd.read_csv('/content/drive/My Drive/DATASETS/en_sentence_templates.csv')\n",
        "#All the identities considered in EAR paper\n",
        "list_identities = [\"lesbian\", \"gay\", \"bisexual\",\"transgender\", \"trans\", \"queer\", \"lgbt\",\"lgbtq\", \"homosexual\", \"straight\", \"heterosexual\",\"male\", \"female\", \"nonbinary\", \"african\",\"african american\", \"black\", \"white\", \"european\",\"hispanic\", \"latino\", \"latina\", \"latinx\", \"mexican\",\"canadian\", \"american\", \"asian\", \"indian\",\"middle eastern\", \"chinese\", \"japanese\", \"christian\",\"muslim\", \"jewish\", \"buddhist\", \"catholic\",\"protestant\", \"sikh\", \"taoist\", \"old\", \"older\", \"young\",\"younger\", \"teenage\", \"millenial\", \"middle aged\",\"elderly\", \"blind\", \"deaf\", \"paralyzed\"]\n",
        "print(len(list_identities))\n",
        "#A sub_list of all the identities\n",
        "gender_sub_list_identities = [\"lesbian\", \"gay\", \"bisexual\",\"transgender\", \"trans\", \"queer\", \"lgbt\",\"lgbtq\", \"homosexual\", \"straight\", \"heterosexual\",\"male\", \"female\", \"nonbinary\"]\n",
        "ethnicity_sub_list_identities = [\"african\",\"african american\", \"black\", \"white\", \"european\",\"hispanic\", \"latino\", \"latina\", \"latinx\", \"mexican\",\"canadian\", \"american\", \"asian\", \"indian\",\"middle eastern\", \"chinese\", \"japanese\"]\n",
        "religion_sub_list_identities = [\"christian\",\"muslim\", \"jewish\", \"buddhist\", \"catholic\",\"protestant\", \"sikh\", \"taoist\"]\n",
        "age_sub_list_identities = [\"old\", \"older\", \"young\",\"younger\", \"teenage\", \"millenial\", \"middle aged\",\"elderly\", \"blind\", \"deaf\", \"paralyzed\"]\n"
      ],
      "metadata": {
        "id": "qUAs7MOib_2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(synthetic_test_df.shape[0])\n",
        "#drop some random names\n",
        "name_drop = ['Êú™Êú™','Zoe','Ziv','Ying','Thel','Sulin','Sooyin','Sohaib','Sara','Santiago','Ram√≥n','Nithum','Myesha','Mukhtar','Morgan','Mohammed','Moeta','Medina','Mateo','Mahir','Lucas','ÏÑúÏú§','Abdul','Agust√≠n','Aishah','Aki','Alva','Anastasiya','Angela','Anita','Baratunde','Binh','Chris','Dlshad','Elizabeth','Emad','Hiro','Hoshi','Ioannis','Javeria','Jim','Joe','L√©','Liam','Ling']\n",
        "# drop the rows that contain the string name in the 'phrase' column\n",
        "for name in name_drop:\n",
        "  synthetic_test_df = synthetic_test_df[~synthetic_test_df['phrase'].str.contains(name)]\n",
        "print(synthetic_test_df.shape[0])"
      ],
      "metadata": {
        "id": "xXiUMFdzcI02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop_identities = list_identities - sub_list_identities\n",
        "drop_identities = [x for x in list_identities if x not in age_sub_list_identities]\n",
        "for identity in drop_identities:\n",
        "  # drop the rows that contain the string identity in the 'phrase' column\n",
        "  synthetic_test_df = synthetic_test_df[~synthetic_test_df['phrase'].str.contains(identity)]\n",
        "print(synthetic_test_df.shape[0])"
      ],
      "metadata": {
        "id": "TjitvltWcQQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute AUC metrics"
      ],
      "metadata": {
        "id": "5b2ztPK58syV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_auc(df:pd.DataFrame):\n",
        "  predictions = []\n",
        "  list_comments = list(df['phrase'])\n",
        "  for comment in list_comments:\n",
        "    result = classifier(comment)\n",
        "    if(result=='TOXIC'):\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "  print(predictions)\n",
        "  df[\"toxicity\"] = df[\"toxicity\"].map({\"nontoxic\": 0, \"toxic\": 1})\n",
        "  return roc_auc_score(df['toxicity'],predictions)"
      ],
      "metadata": {
        "id": "5lTB7RqOcV4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_results = {'subgroup_AUC':[],'BPSN_AUC':[],'BNSP_AUC':[]}\n",
        "for identity in age_sub_list_identities:\n",
        "  print(identity)\n",
        "  subgroup_auc_df = synthetic_test_df.loc[synthetic_test_df['phrase'].str.contains(identity)].copy()\n",
        "  score = compute_auc(subgroup_auc_df)\n",
        "  metrics_results['subgroup_AUC'].append((identity,score))\n",
        "  BPSN_auc_df = synthetic_test_df.loc[((synthetic_test_df['phrase'].str.contains(identity)) & (synthetic_test_df['toxicity'] == 'nontoxic')) | (~(synthetic_test_df['phrase'].str.contains(identity)) & (synthetic_test_df['toxicity'] == 'toxic'))].copy()\n",
        "  score = compute_auc(BPSN_auc_df)\n",
        "  metrics_results['BPSN_AUC'].append((identity,score))\n",
        "  BNSP_auc_df = synthetic_test_df.loc[((synthetic_test_df['phrase'].str.contains(identity)) & (synthetic_test_df['toxicity'] == 'toxic')) | (~(synthetic_test_df['phrase'].str.contains(identity)) & (synthetic_test_df['toxicity'] == 'nontoxic'))].copy()\n",
        "  score = compute_auc(BNSP_auc_df)\n",
        "  metrics_results['BNSP_AUC'].append((identity,score))"
      ],
      "metadata": {
        "id": "LZoh-ylxcYwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_scores(AUC_dict:dict):\n",
        "  #print(AUC_dict)\n",
        "  for metric in AUC_dict:\n",
        "    sum=0\n",
        "    for tup in AUC_dict[metric]:\n",
        "      sum += tup[1]\n",
        "    average = sum/len(AUC_dict[metric])\n",
        "    print('Avg '+metric+': '+str(round(average, 10)))"
      ],
      "metadata": {
        "id": "Yw5_KOQPcco2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_avg_scores(metrics_results)"
      ],
      "metadata": {
        "id": "b-fLtIrDHcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute F1-score on synthetic dataset"
      ],
      "metadata": {
        "id": "vPQg2qEm846k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "synthetic_comments = list(synthetic_test_df['phrase'])\n",
        "synthetic_labels = synthetic_test_df[\"toxicity\"].map({\"nontoxic\": 0, \"toxic\": 1})\n",
        "predictions = []\n",
        "for comment in synthetic_comments:\n",
        "  result = classifier(comment)\n",
        "  if(result=='TOXIC'):\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "print(\"F1-score on synthetic dataset (XLNet 0_00): \"+str(f1_score(synthetic_labels,predictions)))"
      ],
      "metadata": {
        "id": "UCu0sy_b88fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Avg AUC scores for all identities"
      ],
      "metadata": {
        "id": "n53ld9ZyFOGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL_xlnet_ear_reg_0_00 = {'subgroup_AUC': [('lesbian', 0.6616541353383458), ('gay', 0.5075187969924813), ('bisexual', 0.5526315789473684), ('transgender', 0.6992481203007519), ('trans', 0.8233082706766917), ('queer', 0.5864661654135338), ('lgbt', 0.9774436090225564), ('lgbtq', 0.9774436090225564), ('homosexual', 0.5), ('straight', 0.9586466165413533), ('heterosexual', 0.6015037593984962), ('male', 0.9812030075187971), ('female', 0.9849624060150376), ('nonbinary', 0.9661654135338346), ('african', 0.9774436090225563), ('african american', 0.981203007518797), ('black', 0.7969924812030076), ('white', 0.9699248120300752), ('european', 0.9736842105263157), ('hispanic', 0.9699248120300752), ('latino', 0.9473684210526316), ('latina', 0.9473684210526316), ('latinx', 0.9661654135338344), ('mexican', 0.9699248120300752), ('canadian', 0.9736842105263157), ('american', 0.981203007518797), ('asian', 0.9135338345864661), ('indian', 0.9661654135338347), ('middle eastern', 0.9548872180451127), ('chinese', 0.9774436090225564), ('japanese', 0.9736842105263157), ('christian', 0.9887218045112782), ('muslim', 0.9736842105263158), ('jewish', 0.8571428571428572), ('buddhist', 0.9774436090225564), ('catholic', 0.93609022556391), ('protestant', 0.969924812030075), ('sikh', 0.9774436090225564), ('taoist', 0.906015037593985), ('old', 0.9699248120300752), ('older', 0.9624060150375939), ('young', 0.9718045112781954), ('younger', 0.9586466165413534), ('teenage', 0.9548872180451128), ('millenial', 0.9736842105263157), ('middle aged', 0.9736842105263158), ('elderly', 0.981203007518797), ('blind', 0.7819548872180451), ('deaf', 0.612781954887218), ('paralyzed', 0.6278195488721805)], 'BPSN_AUC': [('lesbian', 0.6474840948525158), ('gay', 0.4933487565066512), ('bisexual', 0.5384615384615384), ('transgender', 0.6931752458068248), ('trans', 0.8342731829573934), ('queer', 0.5803932909196068), ('lgbt', 0.9884085213032581), ('lgbtq', 0.9875650665124349), ('homosexual', 0.48582995951417), ('straight', 0.9728166570271833), ('heterosexual', 0.5954308849045691), ('male', 0.9790100250626567), ('female', 0.9829381145170618), ('nonbinary', 0.9843840370156159), ('african', 0.9765664160401002), ('african american', 0.9783834586466165), ('black', 0.7861842105263159), ('white', 0.9671052631578947), ('european', 0.9788533834586466), ('hispanic', 0.9631109022556391), ('latino', 0.9485432330827068), ('latina', 0.9405545112781956), ('latinx', 0.9593515037593985), ('mexican', 0.9790883458646616), ('canadian', 0.9788533834586466), (\n",
        "    'american', 0.9781954887218045), ('asian', 0.918703007518797), ('indian', 0.9673402255639099), ('middle eastern', 0.9600563909774436), ('chinese', 0.9786184210526316), ('japanese', 0.9788533834586466), ('christian', 0.976906552094522), ('muslim', 0.9747583243823845), ('jewish', 0.8582169709989259), ('buddhist', 0.9785177228786252), ('catholic', 0.9371643394199786), ('protestant', 0.9752953813104188), ('sikh', 0.9785177228786252), ('taoist', 0.9070891514500539), ('old', 0.9809941520467836), ('older', 0.9827067669172933), ('young', 0.9828738512949039), ('younger', 0.9830827067669172), ('teenage', 0.9462406015037593), ('millenial', 0.9815789473684211), ('middle aged', 0.9774436090225563), ('elderly', 0.9808270676691729), ('blind', 0.7691729323308271), ('deaf', 0.5958646616541354), ('paralyzed', 0.6150375939849624)], 'BNSP_AUC': [('lesbian', 0.8016194331983806), ('gay', 0.813475997686524), ('bisexual', 0.8100057836899942), ('transgender', 0.7906304222093695), ('trans', 0.7600250626566416), ('queer', 0.799305957200694), ('lgbt', 0.7343358395989975), ('lgbtq', 0.7530364372469636), ('homosexual', 0.8140543666859457), ('straight', 0.7504337767495661), ('heterosexual', 0.7981492192018507), ('male', 0.7468671679197996), ('female', 0.7646038172353962), ('nonbinary', 0.7458068247541932), ('african', 0.9530075187969925), ('african american', 0.9562969924812029), ('black', 0.9757988721804511), ('white', 0.9570018796992481), ('european', 0.9487781954887217), ('hispanic', 0.9609962406015037), ('latino', 0.9544172932330828), ('latina', 0.962406015037594), ('latinx', 0.9612312030075187), ('mexican', 0.9450187969924813), ('canadian', 0.9487781954887217), ('american', 0.9546365914786967), ('asian', 0.9525375939849624), ('indian', 0.9532424812030076), ('middle eastern', 0.949953007518797), ('chinese', 0.9525375939849625), ('japanese', 0.9487781954887217), ('christian', 0.9543501611170784), ('muslim', 0.943609022556391), ('jewish', 0.9602577873254566), ('buddhist', 0.9430719656283566), ('catholic', 0.9489795918367347), ('protestant', 0.9398496240601503), ('sikh', 0.9430719656283566), ('taoist', 0.9532760472610098), ('old', 0.8611111111111109), ('older', 0.8624060150375941), ('young', 0.8606934001670843), ('younger', 0.8586466165413534), ('teenage', 0.8921052631578947), ('millenial', 0.8736842105263157), ('middle aged', 0.8778195488721805), ('elderly', 0.8812030075187971), ('blind', 0.9135338345864661), ('deaf', 0.9345864661654135), ('paralyzed', 0.9289473684210525)]}\n",
        "\n",
        "FINAL_xlnet_ear_reg_0_01 = {'subgroup_AUC': [('lesbian', 0.8533834586466166), ('gay', 0.6992481203007519), ('bisexual', 0.8984962406015038), ('transgender', 0.8984962406015038), ('trans', 0.9135338345864661), ('queer', 0.5939849624060151), ('lgbt', 0.9229323308270676), ('lgbtq', 0.9172932330827067), ('homosexual', 0.5037593984962406), ('straight', 0.8759398496240601), ('heterosexual', 0.868421052631579), ('male', 0.981203007518797), ('female', 0.9924812030075187), ('nonbinary', 0.9135338345864661), ('african', 0.9680451127819549), ('african american', 0.9624060150375939), ('black', 0.9360902255639098), ('white', 0.9060150375939849), ('european', 0.9624060150375939), ('hispanic', 0.8609022556390977), ('latino', 0.9210526315789475), ('latina', 0.9022556390977443), ('latinx', 0.9097744360902256), ('mexican', 0.9060150375939849), ('canadian', 0.9398496240601503), ('american', 0.9736842105263158), ('asian', 0.9285714285714285), ('indian', 0.951127819548872), ('middle eastern', 0.87593984962406), ('chinese', 0.9661654135338346), ('japanese', 0.9285714285714285), ('christian', 0.9774436090225564), ('muslim', 0.9511278195488723), ('jewish', 0.9097744360902255), ('buddhist', 0.9360902255639098), ('catholic', 0.8947368421052632), ('protestant', 0.9248120300751879), ('sikh', 0.9661654135338347), ('taoist', 0.9060150375939849), ('old', 0.8759398496240602), ('older', 0.8646616541353384), ('young', 0.8909774436090225), ('younger', 0.8796992481203008), ('teenage', 0.9548872180451128), ('millenial', 0.8721804511278194), ('middle aged', 0.8796992481203008), ('elderly', 0.9436090225563909), ('blind', 0.9285714285714284), ('deaf', 0.9022556390977443), ('paralyzed', 0.9022556390977443)], 'BPSN_AUC': [('lesbian', 0.8241758241758242), ('gay', 0.6700404858299596), ('bisexual', 0.8692886061307115), ('transgender', 0.8692886061307115), ('trans', 0.919172932330827), ('queer', 0.5647773279352226), ('lgbt', 0.9548872180451128), ('lgbtq', 0.9609600925390399), ('homosexual', 0.47455176402544824), ('straight', 0.9762868710237129), ('heterosexual', 0.8392134181607868), ('male', 0.9495614035087718), ('female', 0.9632735685367264), ('nonbinary', 0.9774436090225564), ('african', 0.9106516290726817), ('african american', 0.9046052631578948), ('black', 0.8982612781954887), ('white', 0.9241071428571428), ('european', 0.9405545112781953), ('hispanic', 0.9508928571428572), ('latino', 0.90718984962406), ('latina', 0.9363251879699248), ('latinx', 0.9039003759398496), ('mexican', 0.9480733082706767), (\n",
        "    'canadian', 0.9419642857142856), ('american', 0.918421052631579), ('asian', 0.9306860902255639), ('indian', 0.9412593984962405), ('middle eastern', 0.9419642857142857), ('chinese', 0.9403195488721803), ('japanese', 0.9426691729323308), ('christian', 0.9215896885069818), ('muslim', 0.9210526315789475), ('jewish', 0.9355531686358753), ('buddhist', 0.9360902255639098), ('catholic', 0.9591836734693877), ('protestant', 0.9334049409237379), ('sikh', 0.9360902255639099), ('taoist', 0.9232008592910849), ('old', 0.9342105263157895), ('older', 0.9315789473684211), ('young', 0.9331662489557226), ('younger', 0.9300751879699248), ('teenage', 0.8977443609022557), ('millenial', 0.9266917293233082), ('middle aged', 0.8969924812030075), ('elderly', 0.9236842105263158), ('blind', 0.88796992481203), ('deaf', 0.8285714285714285), ('paralyzed', 0.8409774436090225)], 'BNSP_AUC': [('lesbian', 0.8744939271255061), ('gay', 0.8863504916136495), ('bisexual', 0.8710237131289763), ('transgender', 0.8710237131289763), ('trans', 0.8289473684210527), ('queer', 0.8944476576055523), ('lgbt', 0.8010651629072681), ('lgbtq', 0.7967032967032966), ('homosexual', 0.9013880855986119), ('straight', 0.7432041642567958), ('heterosexual', 0.8733371891266628), ('male', 0.8549498746867168), ('female', 0.8637941006362059), ('nonbinary', 0.7767495662232503), ('african', 0.9827067669172931), ('african american', 0.9861372180451128), ('black', 0.9678101503759398), ('white', 0.9137687969924813), ('european', 0.950187969924812), ('hispanic', 0.8446898496240601), ('latino', 0.9447838345864662), ('latina', 0.8980263157894736), ('latinx', 0.9375), ('mexican', 0.8898026315789473), ('canadian', 0.9276315789473684), ('american', 0.9798245614035087), ('asian', 0.9283364661654134), ('indian', 0.9389097744360902), ('middle eastern', 0.8677161654135337), ('chinese', 0.9539473684210527), ('japanese', 0.9163533834586467), ('christian', 0.9828141783029002), ('muslim', 0.9607948442534909), ('jewish', 0.9108485499462943), ('buddhist', 0.9328678839957036), ('catholic', 0.8743286788399569), ('protestant', 0.9258861439312566), ('sikh', 0.9586466165413533), ('taoist', 0.9199785177228785), ('old', 0.8489974937343359), ('older', 0.8383458646616542), ('young', 0.8617376775271512), ('younger', 0.8533834586466167), ('teenage', 0.9533834586466166), ('millenial', 0.85), ('middle aged', 0.8864661654135338), ('elderly', 0.9172932330827068), ('blind', 0.9394736842105262), ('deaf', 0.975187969924812), ('paralyzed', 0.9627819548872181)]}\n",
        "\n",
        "print(\"FINAL_xlnet_ear_reg_0_00\")\n",
        "compute_avg_scores(FINAL_xlnet_ear_reg_0_00)\n",
        "print(\"FINAL_xlnet_ear_reg_0_01\")\n",
        "compute_avg_scores(FINAL_xlnet_ear_reg_0_01)"
      ],
      "metadata": {
        "id": "CN87fSbcFOYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}